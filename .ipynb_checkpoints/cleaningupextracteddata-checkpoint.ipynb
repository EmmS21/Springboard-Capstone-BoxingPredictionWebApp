{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import glob\n",
    "import numpy as np\n",
    "file = pd.concat([pd.read_csv(f, index_col=None,header=None) for f in glob.glob('C:\\\\Users\\\\User\\\\Documents\\\\datasets\\\\fin*.csv')])\n",
    "file2  = pd.concat([pd.read_csv(f, index_col=None,header=None) for f in glob.glob('C:\\\\Users\\\\User\\\\Documents\\\\datasets\\\\final*.csv')])\n",
    "file_full = pd.concat([file,file2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns of interest\n",
    "# ax = boxing[boxing.columns[-3225:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(file_full[file_full.columns[0:]].apply(lambda x: ' '.join(x.astype(str)),axis=1))\n",
    "df = pd.DataFrame(df[0].str.replace('date','dateday'))\n",
    "#split each fight into a separate column\n",
    "df_split = pd.DataFrame(df[0].str.split('date',expand=True))\n",
    "def func(df,col):\n",
    "    return df[col].str.extract('day(?P<day>.*?)firstBoxerRating(?P<firstBoxerRating>.*?)firstBoxerWeight(?P<firstBoxerWeight>.*?)judges(?P<JudgeID>.*?)links(?P<Links>.*?)location(?P<location>.*?)metadata(?P<metadata>.*?)numberOfRounds(?P<numberofrounds>.*?)outcome(?P<outcome>.*?)rating(?P<rating>.*?)referee(?P<referee>.*?)secondBoxer(?P<secondBoxer>.*?)secondBoxerLast6(?P<secondBoxerLast6>.*?)secondBoxerRating(?P<secondBoxerRating>.*?)secondBoxerRecord(?P<secondBoxerRecord>.*?)secondBoxerWeight(?P<secondBoxerWeight>.*?)titles(?P<titles>.*?){')\n",
    "for i in range(1,len(df_split.columns)-1):\n",
    "    df_split[['date'+str(i), 'firstBoxerRating'+str(i), 'firstBoxerWeight'+str(i), 'JudgeID'+str(i), 'Links'+str(i),\n",
    "       'location'+str(i), 'metadata'+str(i), 'numberofrounds'+str(i), 'outcome'+str(i), 'rating'+str(i),\n",
    "       'referee'+str(i), 'secondBoxer'+str(i), 'secondBoxerLast6'+str(i), 'secondBoxerRating'+str(i),\n",
    "       'secondBoxerRecord'+str(i), 'secondBoxerWeight'+str(i), 'titles'+str(i)]] = func(df_split,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['titles'+str(i) for i in range(1,85)]\n",
    "masked = df_split[titles].astype(str)\n",
    "df_split['global_id']=masked.apply(','.join,axis=1).str.extract(r'(\\d{6})', expand = False).fillna('')\n",
    "# df_split['global_id'] = masked.apply(','.join,axis=1).str.extract(r'(\\d{4})', expand = False).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = pd.read_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\datasets\\\\df2.csv\")\n",
    "new_file['global_id'] = new_file.players_links.str.extract('(\\d+)')\n",
    "new_file['global_id'] = new_file.global_id.astype('float64')\n",
    "df_split['global_id'] = pd.to_numeric(df_split['global_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(new_file, df_split, how='outer', on='global_id')\n",
    "merged.drop_duplicates(subset='global_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning up data\n",
    "def date_clean(date_col):\n",
    "    x = merged[date_col].str.replace('[\":]','')\n",
    "    return pd.to_datetime(x,errors='coerce')\n",
    "#create list of column names we want to iterate through\n",
    "def list_var(col_name):\n",
    "    return [col_name+str(i) for i in range(1,85)]\n",
    "#update date columns\n",
    "var_names = list_var('date')\n",
    "for i in var_names:\n",
    "    merged[i] = date_clean(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup first boxer rating\n",
    "def remove_colon(col_name):\n",
    "    return merged[col_name].str.replace(':','')\n",
    "#weights need to be converted to float\n",
    "def firstweight(col_name):\n",
    "    a = remove_colon(col_name)\n",
    "    return pd.to_numeric(a,errors='coerce')\n",
    "#extract scorecard from judges column\n",
    "def score_card(col_name):\n",
    "    return merged[col_name].str.findall('scorecard:(?P<scorecards>.*?)}')\n",
    "#update first boxer rating columns\n",
    "boxer_var = list_var('firstBoxerRating')\n",
    "for i in boxer_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "#update weight\n",
    "weight_var = list_var('firstBoxerWeight')\n",
    "for i in weight_var:\n",
    "    merged[i] = firstweight(i)\n",
    "#extract score card\n",
    "scorecard_var = list_var('JudgeID')\n",
    "for i in scorecard_var:\n",
    "    merged[i] = score_card(i)\n",
    "#update location\n",
    "location_var = list_var('location')\n",
    "for i in location_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "#update num of rounds\n",
    "rounds_var = list_var('numberofrounds')\n",
    "for i in rounds_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "#update outcome\n",
    "outcome_var = list_var('outcome')\n",
    "for i in outcome_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "#update rating\n",
    "rating_var = list_var('rating')\n",
    "for i in rating_var:\n",
    "    merged[i] = remove_colon(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function creates errors so trying for loop instead\n",
    "ref_outcome = list_var('referee')\n",
    "for i in ref_outcome:\n",
    "    merged[i] = merged[i].str.findall('result:(?P<result>.*?)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondboxer_var = list_var('secondBoxer')\n",
    "for i in secondboxer_var:\n",
    "    merged[i] = merged[i].str.extract('name:(?P<name>.*?)}')\n",
    "secondboxlast_var = list_var('secondBoxerLast6')\n",
    "for i in secondboxlast_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "secondboxrate_var = list_var('secondBoxerRating')\n",
    "for i in secondboxrate_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "secondboxrec_var = list_var('secondBoxerRecord')\n",
    "for i in secondboxrec_var:\n",
    "    merged[i] = remove_colon(i)\n",
    "secondboxweight_var = list_var('secondBoxerWeight')\n",
    "for i in secondboxweight_var:\n",
    "    merged[i] = firstweight(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract time from metadata\n",
    "def split_time(col):\n",
    "    return merged[col].str.extract('(\\d*\\:\\d+)',expand=True)\n",
    "time_list = list_var('metadata')\n",
    "for i in time_list:\n",
    "    merged[i] = split_time(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = list(range(0,86))\n",
    "merged.drop(drop_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(['level_0','miles'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>division</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>...</th>\n",
       "      <th>win DQ</th>\n",
       "      <th>win KO</th>\n",
       "      <th>win MD</th>\n",
       "      <th>win PTS</th>\n",
       "      <th>win RTD</th>\n",
       "      <th>win SD</th>\n",
       "      <th>win TD</th>\n",
       "      <th>win TKO</th>\n",
       "      <th>win UD</th>\n",
       "      <th>win nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>258</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Chante Bowens</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feather</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>261</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Paris Liles</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>heavy</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>264</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Jerome Woods</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>super middle</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>267</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Tjuan Wooten</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>light</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>270</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Travoris Lofton</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cruiser</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>10116</td>\n",
       "      <td>USA, Hawaii, Molokai</td>\n",
       "      <td>Kawelo Alcos</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>light fly</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>10118</td>\n",
       "      <td>USA, Hawaii, Honolulu</td>\n",
       "      <td>Logan Yoon</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>10120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>11240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>11246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3759 rows × 1469 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                     location             name   sex     w    l  \\\n",
       "86    258    USA, North Carolina, Wilson  Chante Bowens    male  0.0   4.0   \n",
       "87    261    USA, North Carolina, Wilson  Paris Liles      male  0.0   1.0   \n",
       "88    264    USA, North Carolina, Wilson  Jerome Woods     male  0.0   2.0   \n",
       "89    267    USA, North Carolina, Wilson  Tjuan Wooten     male  0.0   1.0   \n",
       "90    270    USA, North Carolina, Wilson  Travoris Lofton  male  0.0   1.0   \n",
       "...   ...                            ...              ...   ...  ...   ...   \n",
       "3840  10116  USA, Hawaii, Molokai         Kawelo Alcos     male  2.0   0.0   \n",
       "3841  10118  USA, Hawaii, Honolulu        Logan Yoon       male  16.0  0.0   \n",
       "3842  10120  NaN                          NaN              NaN  NaN   NaN    \n",
       "3843  11240  NaN                          NaN              NaN  NaN   NaN    \n",
       "3844  11246  NaN                          NaN              NaN  NaN   NaN    \n",
       "\n",
       "        d      division    from      to  ... win DQ  win KO win MD win PTS  \\\n",
       "86    0.0  feather       2018.0  2019.0  ...  0.0    0.0     0.0    0.0      \n",
       "87    0.0  heavy         2019.0  2019.0  ...  0.0    0.0     0.0    0.0      \n",
       "88    0.0  super middle  2019.0  2019.0  ...  0.0    0.0     0.0    0.0      \n",
       "89    0.0  light         2019.0  2019.0  ...  0.0    0.0     0.0    0.0      \n",
       "90    0.0  cruiser       2019.0  2019.0  ...  0.0    0.0     0.0    0.0      \n",
       "...   ...      ...          ...     ...  ...  ...    ...     ...    ...      \n",
       "3840  2.0  light fly     2017.0  2019.0  ...  0.0    0.0     1.0    0.0      \n",
       "3841  0.0  welter        2016.0  2019.0  ...  0.0    2.0     0.0    0.0      \n",
       "3842 NaN   NaN          NaN     NaN      ...  0.0    0.0     0.0    0.0      \n",
       "3843 NaN   NaN          NaN     NaN      ...  0.0    1.0     0.0    0.0      \n",
       "3844 NaN   NaN          NaN     NaN      ...  0.0    0.0     4.0    0.0      \n",
       "\n",
       "      win RTD win SD win TD win TKO win UD win nan  \n",
       "86    0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "87    0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "88    0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "89    0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "90    0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "...   ...      ...    ...    ...     ...    ...     \n",
       "3840  0.0      0.0    0.0    1.0     0.0    0.0     \n",
       "3841  1.0      0.0    0.0    9.0     4.0    0.0     \n",
       "3842  0.0      0.0    0.0    0.0     0.0    0.0     \n",
       "3843  0.0      0.0    0.0    4.0     1.0    0.0     \n",
       "3844  3.0      2.0    0.0    8.0     26.0   0.0     \n",
       "\n",
       "[3759 rows x 1469 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create columns with counts of outcomes from referee\n",
    "ref_outcomes = list_var('referee')\n",
    "merged2 = pd.concat([merged,merged[ref_outcome].astype(str).stack().str.replace('\\[|\\\"','').str.extract('(\\w+\\s\\w+)').groupby(level=0)[0].apply(pd.Series.value_counts).unstack(fill_value=0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>location</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>w</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>division</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofrounds84</th>\n",
       "      <th>outcome84</th>\n",
       "      <th>rating84</th>\n",
       "      <th>referee84</th>\n",
       "      <th>secondBoxer84</th>\n",
       "      <th>secondBoxerLast684</th>\n",
       "      <th>secondBoxerRating84</th>\n",
       "      <th>secondBoxerRecord84</th>\n",
       "      <th>secondBoxerWeight84</th>\n",
       "      <th>titles84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>258</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Chante Bowens</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>feather</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>261</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Paris Liles</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>heavy</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>264</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Jerome Woods</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>super middle</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>267</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Tjuan Wooten</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>light</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>270</td>\n",
       "      <td>USA, North Carolina, Wilson</td>\n",
       "      <td>Travoris Lofton</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cruiser</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>10116</td>\n",
       "      <td>USA, Hawaii, Molokai</td>\n",
       "      <td>Kawelo Alcos</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>light fly</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>10118</td>\n",
       "      <td>USA, Hawaii, Honolulu</td>\n",
       "      <td>Logan Yoon</td>\n",
       "      <td>male</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>welter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>10120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>11240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>11246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3759 rows × 1440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                     location             name   sex     w    l  \\\n",
       "86    258    USA, North Carolina, Wilson  Chante Bowens    male  0.0   4.0   \n",
       "87    261    USA, North Carolina, Wilson  Paris Liles      male  0.0   1.0   \n",
       "88    264    USA, North Carolina, Wilson  Jerome Woods     male  0.0   2.0   \n",
       "89    267    USA, North Carolina, Wilson  Tjuan Wooten     male  0.0   1.0   \n",
       "90    270    USA, North Carolina, Wilson  Travoris Lofton  male  0.0   1.0   \n",
       "...   ...                            ...              ...   ...  ...   ...   \n",
       "3840  10116  USA, Hawaii, Molokai         Kawelo Alcos     male  2.0   0.0   \n",
       "3841  10118  USA, Hawaii, Honolulu        Logan Yoon       male  16.0  0.0   \n",
       "3842  10120  NaN                          NaN              NaN  NaN   NaN    \n",
       "3843  11240  NaN                          NaN              NaN  NaN   NaN    \n",
       "3844  11246  NaN                          NaN              NaN  NaN   NaN    \n",
       "\n",
       "        d      division    from      to  ... numberofrounds84  outcome84  \\\n",
       "86    0.0  feather       2018.0  2019.0  ...  NaN              NaN         \n",
       "87    0.0  heavy         2019.0  2019.0  ...  NaN              NaN         \n",
       "88    0.0  super middle  2019.0  2019.0  ...  NaN              NaN         \n",
       "89    0.0  light         2019.0  2019.0  ...  NaN              NaN         \n",
       "90    0.0  cruiser       2019.0  2019.0  ...  NaN              NaN         \n",
       "...   ...      ...          ...     ...  ...  ...              ...         \n",
       "3840  2.0  light fly     2017.0  2019.0  ...  NaN              NaN         \n",
       "3841  0.0  welter        2016.0  2019.0  ...  NaN              NaN         \n",
       "3842 NaN   NaN          NaN     NaN      ...  NaN              NaN         \n",
       "3843 NaN   NaN          NaN     NaN      ...  NaN              NaN         \n",
       "3844 NaN   NaN          NaN     NaN      ...  NaN              NaN         \n",
       "\n",
       "     rating84 referee84  secondBoxer84 secondBoxerLast684 secondBoxerRating84  \\\n",
       "86    NaN      NaN       NaN            NaN                NaN                  \n",
       "87    NaN      NaN       NaN            NaN                NaN                  \n",
       "88    NaN      NaN       NaN            NaN                NaN                  \n",
       "89    NaN      NaN       NaN            NaN                NaN                  \n",
       "90    NaN      NaN       NaN            NaN                NaN                  \n",
       "...   ...      ...       ...            ...                ...                  \n",
       "3840  NaN      NaN       NaN            NaN                NaN                  \n",
       "3841  NaN      NaN       NaN            NaN                NaN                  \n",
       "3842  NaN      NaN       NaN            NaN                NaN                  \n",
       "3843  NaN      NaN       NaN            NaN                NaN                  \n",
       "3844  NaN      NaN       NaN            NaN                NaN                  \n",
       "\n",
       "     secondBoxerRecord84 secondBoxerWeight84 titles84  \n",
       "86    NaN                NaN                  NaN      \n",
       "87    NaN                NaN                  NaN      \n",
       "88    NaN                NaN                  NaN      \n",
       "89    NaN                NaN                  NaN      \n",
       "90    NaN                NaN                  NaN      \n",
       "...   ...                 ..                  ...      \n",
       "3840  NaN                NaN                  NaN      \n",
       "3841  NaN                NaN                  NaN      \n",
       "3842  NaN                NaN                  NaN      \n",
       "3843  NaN                NaN                  NaN      \n",
       "3844  NaN                NaN                  NaN      \n",
       "\n",
       "[3759 rows x 1440 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract scorecards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.drop(['players_links'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = list_var('outcome')\n",
    "#remove quotation marks from outcomes column\n",
    "merged[outcomes] = merged[outcomes].astype('str').apply(lambda s:s.str.replace('\"', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = merged[merged['name'] == 'Deontay Wilder']\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df_split[df_split['global_id'] == 0]\n",
    "# x.iloc[2].to_dict()\n",
    "file_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[outcomes].astype('str').unstack()\n",
    "# .str.replace('\\[|\\\"','').str.extract('(\\w+\\s\\w+)').groupby(level=0)[0].apply(pd.Series.value_counts).unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract outcomes from data in judge column and merge with original dataset\n",
    "enriched_data2 = pd.concat([enriched_data,enriched_data[ref_outcome].astype(str).stack().str.replace('\\[|\\\"','').str.extract('(\\w+\\s\\w+)').groupby(level=0)[0].apply(pd.Series.value_counts).unstack(fill_value=0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data2.drop_duplicates(subset=['name','global_id'],keep='first',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data2 = enriched_data2.rename(columns={'3':'city','4':'state/country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining with other data\n",
    "player_profile = pd.read_csv(\"C:\\\\Users\\\\User\\\\Documents\\\\datasets\\\\player_profile.csv\")\n",
    "player_profile.drop_duplicates(subset=['Name'],keep='first',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppcols = player_profile[['stance','nationality','debut','Name','status','age','height','residence','KOs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more cleanup, extracting judge's scorecards\n",
    "def judge_scores(col_name):\n",
    "    return enriched_data2.JudgeID2.apply(pd.Series)\n",
    "col_names = list(chain.from_iterable(('first'+str(i),'second'+str(i),'third'+str(i)) for i in range(1,80)))\n",
    "score_vars = list_var('JudgeID')\n",
    "for i in score_vars:\n",
    "    for x,y,z in zip(*[iter(col_names)]*3):\n",
    "        enriched_data2[[x,y,z]] = judge_scores(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = enriched_data2.merge(ppcols, how='left',left_on='name',right_on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('C:\\\\Users\\\\User\\\\Documents\\\\enriched_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_scores(col_name):\n",
    "    return enriched_data.JudgeID2.apply(pd.Series)\n",
    "col_names = list(chain.from_iterable(('first'+str(i),'second'+str(i),'third'+str(i)) for i in range(1,80)))\n",
    "score_vars = list_var('JudgeID')\n",
    "for i in score_vars:\n",
    "    for x,y,z in zip(*[iter(col_names)]*3):\n",
    "        enriched_data[[x,y,z]] = judge_scores(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enriched_data['JudgeID2'].values.tolist()\n",
    "b = pd.DataFrame(a.JudgeID2)\n",
    "enriched_data.JudgeID2.apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test['JudgeID2'].apply(np.ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a  = test['JudgeID2'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(test.JudgeID2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(([c[0] for c in r] for r in a.JudgeID2.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([x for _list in a.JudgeID2 for x in _list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a.explode('JudgeID2')).reset_index()\n",
    "df.pivot_table(columns='index',values='JudgeID2',aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['team1','team2','team3']] = pd.DataFrame(a.JudgeID2.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
